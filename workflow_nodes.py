from typing import TypedDict, List, Dict, Any
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import requests
import streamlit as st
import os
import json
from enhanced_news_fetcher import EnhancedNewsAPI

class WorkflowState(TypedDict):
    keyword: str
    selected_publishers: List[str]
    raw_articles: Dict[str, List[Dict[str, Any]]]
    analyzed_articles: Dict[str, List[Dict[str, Any]]]
    comparison_analysis: Dict[str, Any]
    final_report: str
    usage_suggestions: List[str]

class NewsWorkflowNodes:
    def __init__(self):
        # ì•ˆì „í•œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        try:
            # Streamlit Cloud í™˜ê²½
            if hasattr(st, 'secrets') and len(st.secrets) > 0:
                api_key = st.secrets.get("OPENAI_API_KEY", "")
            else:
                # ë¡œì»¬ í™˜ê²½ (í™˜ê²½ë³€ìˆ˜)
                api_key = os.getenv("OPENAI_API_KEY", "")
                
            if api_key:
                self.llm = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    temperature=0.3,
                    api_key=api_key
                )
            else:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
            
        self.enhanced_news_api = EnhancedNewsAPI()
        self.all_publishers = ['ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸', 'SBS', 'MBC', 'KBS']

    def decide_publishers(self, state: WorkflowState) -> WorkflowState:
        """
        1ë‹¨ê³„: í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ì–¸ë¡ ì‚¬ë¥¼ ê²°ì •
        """
        keyword = state["keyword"]
        
        if not self.llm:
            # LLMì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì–¸ë¡ ì‚¬ ì„ íƒ
            selected_publishers = ['ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸']
            print(f"ê¸°ë³¸ ì–¸ë¡ ì‚¬ ì„ íƒ: {selected_publishers}")
            state["selected_publishers"] = selected_publishers
            return state
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì— ì í•©í•œ ì–¸ë¡ ì‚¬ ì„ íƒ
        prompt = f"""
        ë‹¤ìŒ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ ê°€ì¥ ì í•©í•œ í•œêµ­ ì–¸ë¡ ì‚¬ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

        í‚¤ì›Œë“œ: "{keyword}"

        ì„ íƒ ê°€ëŠ¥í•œ ì–¸ë¡ ì‚¬: {', '.join(self.all_publishers)}

        ë‹¤ìŒ ê¸°ì¤€ì„ ê³ ë ¤í•˜ì—¬ 4-6ê°œ ì–¸ë¡ ì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:
        1. í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ë³´ë„ ë¹ˆë„
        2. ì •ì¹˜ì  ì„±í–¥ì˜ ë‹¤ì–‘ì„± (ë³´ìˆ˜, ì§„ë³´, ì¤‘ë„)
        3. ë§¤ì²´ ìœ í˜•ì˜ ë‹¤ì–‘ì„± (ì‹ ë¬¸, ë°©ì†¡)

        ì‘ë‹µ í˜•ì‹: ["ì–¸ë¡ ì‚¬1", "ì–¸ë¡ ì‚¬2", "ì–¸ë¡ ì‚¬3", ...]
        """
        
        try:
            response = self.llm.invoke([
                SystemMessage(content="ë‹¹ì‹ ì€ í•œêµ­ ì–¸ë¡  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                HumanMessage(content=prompt)
            ])
            
            # LLM ì‘ë‹µì—ì„œ ì–¸ë¡ ì‚¬ ëª©ë¡ ì¶”ì¶œ
            content = response.content
            # JSON í˜•íƒœë¡œ íŒŒì‹± ì‹œë„
            try:
                if '[' in content and ']' in content:
                    start = content.find('[')
                    end = content.rfind(']') + 1
                    publishers_str = content[start:end]
                    selected_publishers = json.loads(publishers_str)
                else:
                    # fallback: ê¸°ë³¸ ì–¸ë¡ ì‚¬ ì„ íƒ
                    selected_publishers = ['ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸']
            except:
                selected_publishers = ['ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸']
                
        except Exception as e:
            print(f"ì–¸ë¡ ì‚¬ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            selected_publishers = ['ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸']
        
        print(f"ì„ íƒëœ ì–¸ë¡ ì‚¬: {selected_publishers}")
        state["selected_publishers"] = selected_publishers
        return state

    def collect_articles(self, state: WorkflowState) -> WorkflowState:
        """
        2ë‹¨ê³„: ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ê¸°ì‚¬ ìˆ˜ì§‘
        """
        keyword = state["keyword"]
        publishers = state["selected_publishers"]
        
        print(f"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ê¸°ì‚¬ ìˆ˜ì§‘ ì‹œì‘: {keyword}")
        
        try:
            # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘ ë°©ì‹ ì‚¬ìš©
            raw_articles = self.enhanced_news_api.collect_articles_hybrid(keyword, publishers)
            
            # ìˆ˜ì§‘ ê²°ê³¼ ì¶œë ¥
            total_collected = sum(len(articles) for articles in raw_articles.values())
            print(f"ğŸ“Š ì´ {total_collected}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
            
            for publisher, articles in raw_articles.items():
                sources = {}
                for article in articles:
                    source = article.get('source', 'unknown')
                    sources[source] = sources.get(source, 0) + 1
                
                source_info = ", ".join([f"{k}:{v}" for k, v in sources.items()])
                print(f"  {publisher}: {len(articles)}ê°œ ({source_info})")
            
            # ë§Œì•½ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ë„ˆë¬´ ì ë‹¤ë©´ ìƒ˜í”Œ ê¸°ì‚¬ë¡œ ë³´ì™„
            if total_collected < 5:
                print("ğŸ”„ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ë¶€ì¡±í•˜ì—¬ ìµœì‹  ìƒ˜í”Œ ê¸°ì‚¬ë¡œ ë³´ì™„í•©ë‹ˆë‹¤...")
                sample_articles = self.enhanced_news_api.get_sample_articles(publishers)
                
                for publisher in publishers:
                    if len(raw_articles.get(publisher, [])) == 0 and sample_articles.get(publisher):
                        raw_articles[publisher] = sample_articles[publisher][:2]  # ìµœëŒ€ 2ê°œ
                        print(f"  {publisher}: ìƒ˜í”Œ ê¸°ì‚¬ {len(raw_articles[publisher])}ê°œ ì¶”ê°€")
            
        except Exception as e:
            print(f"ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            # ë¹ˆ ê²°ê³¼ë¡œ ì´ˆê¸°í™”
            raw_articles = {pub: [] for pub in publishers}
        
        state["raw_articles"] = raw_articles
        return state

    def analyze_articles(self, state: WorkflowState) -> WorkflowState:
        """
        3-4ë‹¨ê³„: ê¸°ì‚¬ ìš”ì•½ ë° ì–´ì¡°/ê°ì •/ë…¼ì  ë¶„ì„
        """
        raw_articles = state["raw_articles"]
        analyzed_articles = {}
        
        for publisher, articles in raw_articles.items():
            print(f"{publisher} ê¸°ì‚¬ ë¶„ì„ ì¤‘...")
            analyzed_articles[publisher] = []
            
            for article in articles:
                analysis_prompt = f"""
ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

ì œëª©: {article['title']}
ë‚´ìš©: {article['description']}
ì¶œì²˜: {article.get('source', 'unknown')}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:

ìš”ì•½: [3ì¤„ ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½]
ì–´ì¡°: [ê°ê´€ì /ë¹„íŒì /ì˜¹í˜¸ì /ì¤‘ë¦½ì  ì¤‘ í•˜ë‚˜]
ê°ì •: [ê¸ì •ì /ì¤‘ë¦½ì /ë¶€ì •ì  ì¤‘ í•˜ë‚˜]
ì£¼ìš”ë…¼ì : [ì´ ê¸°ì‚¬ê°€ ê°•ì¡°í•˜ëŠ” í•µì‹¬ ì£¼ì¥ì´ë‚˜ ê´€ì ]
í‚¤ì›Œë“œ: [ê¸°ì‚¬ì˜ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„]
"""
                
                try:
                    response = self.llm.invoke([
                        SystemMessage(content="ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."),
                        HumanMessage(content=analysis_prompt)
                    ])
                    
                    analysis = self._parse_article_analysis(response.content)
                    
                    analyzed_article = article.copy()
                    analyzed_article.update(analysis)
                    analyzed_articles[publisher].append(analyzed_article)
                    
                except Exception as e:
                    print(f"ê¸°ì‚¬ ë¶„ì„ ì˜¤ë¥˜: {e}")
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ ì €ì¥
                    analyzed_article = article.copy()
                    analyzed_article.update({
                        'summary': 'ë¶„ì„ ë¶ˆê°€',
                        'tone': 'ì¤‘ë¦½ì ',
                        'sentiment': 'ì¤‘ë¦½ì ',
                        'main_argument': 'ë¶„ì„ ë¶ˆê°€',
                        'keywords': []
                    })
                    analyzed_articles[publisher].append(analyzed_article)
        
        state["analyzed_articles"] = analyzed_articles
        return state

    def compare_analysis(self, state: WorkflowState) -> WorkflowState:
        """
        5ë‹¨ê³„: ì–¸ë¡ ì‚¬ë³„ ì…ì¥ ì°¨ì´ ë° ê°•ì¡°ì  ë¹„êµ ë¶„ì„
        """
        analyzed_articles = state["analyzed_articles"]
        keyword = state["keyword"]
        
        # ì–¸ë¡ ì‚¬ë³„ ìš”ì•½ ì •ë³´ ìƒì„±
        publisher_summaries = {}
        for publisher, articles in analyzed_articles.items():
            if articles:
                summaries = [art.get('summary', '') for art in articles]
                tones = [art.get('tone', '') for art in articles]
                sentiments = [art.get('sentiment', '') for art in articles]
                arguments = [art.get('main_argument', '') for art in articles]
                
                publisher_summaries[publisher] = {
                    'article_count': len(articles),
                    'summaries': summaries,
                    'dominant_tone': max(set(tones), key=tones.count) if tones else 'ì¤‘ë¦½ì ',
                    'dominant_sentiment': max(set(sentiments), key=sentiments.count) if sentiments else 'ì¤‘ë¦½ì ',
                    'main_arguments': arguments
                }
        
        # LLMì„ ì‚¬ìš©í•œ ë¹„êµ ë¶„ì„
        comparison_prompt = f"""
í‚¤ì›Œë“œ "{keyword}"ì— ëŒ€í•œ ì–¸ë¡ ì‚¬ë³„ ë³´ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”.

{json.dumps(publisher_summaries, ensure_ascii=False, indent=2)}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì „ì²´ì ì¸ ë³´ë„ í†¤ì˜ ì°¨ì´
2. ê°•ì¡°í•˜ëŠ” ë…¼ì ì˜ ì°¨ì´
3. ê°ì •ì  ì ‘ê·¼ì˜ ì°¨ì´
4. ê° ì–¸ë¡ ì‚¬ì˜ íŠ¹ì§•ì  ê´€ì 

ì‘ë‹µ í˜•ì‹:
ë³´ë„í†¤_ì°¨ì´: [ì–¸ë¡ ì‚¬ë³„ ë³´ë„ í†¤ ë¹„êµ]
ë…¼ì _ì°¨ì´: [ì–¸ë¡ ì‚¬ë³„ ì£¼ìš” ë…¼ì  ì°¨ì´]
ê°ì •_ì°¨ì´: [ì–¸ë¡ ì‚¬ë³„ ê°ì •ì  ì ‘ê·¼ ì°¨ì´]
íŠ¹ì§•ì _ê´€ì : [ê° ì–¸ë¡ ì‚¬ì˜ ë…íŠ¹í•œ ì‹œê°]
ì¢…í•©_ë¶„ì„: [ì „ì²´ì ì¸ ì–¸ë¡ ì‚¬ ê°„ ì°¨ì´ì  ì¢…í•©]
"""
        
        try:
            response = self.llm.invoke([
                SystemMessage(content="ë‹¹ì‹ ì€ ë¯¸ë””ì–´ í”„ë ˆì´ë° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
                HumanMessage(content=comparison_prompt)
            ])
            
            comparison_analysis = self._parse_comparison_analysis(response.content)
            
        except Exception as e:
            print(f"ë¹„êµ ë¶„ì„ ì˜¤ë¥˜: {e}")
            comparison_analysis = {
                'tone_differences': 'ë¶„ì„ ë¶ˆê°€',
                'argument_differences': 'ë¶„ì„ ë¶ˆê°€',
                'emotional_differences': 'ë¶„ì„ ë¶ˆê°€',
                'unique_perspectives': 'ë¶„ì„ ë¶ˆê°€',
                'overall_analysis': 'ë¶„ì„ ë¶ˆê°€'
            }
        
        state["comparison_analysis"] = comparison_analysis
        return state

    def generate_report(self, state: WorkflowState) -> WorkflowState:
        """
        6ë‹¨ê³„: ë¹„êµ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œ/ë³´ê³ ì„œ í˜•íƒœë¡œ ì •ë¦¬
        """
        keyword = state["keyword"]
        analyzed_articles = state["analyzed_articles"]
        comparison_analysis = state["comparison_analysis"]
        
        # ë³´ê³ ì„œ ìƒì„±
        report = f"""# "{keyword}" ì–¸ë¡ ì‚¬ ë³´ë„ ë¹„êµ ë¶„ì„ ë³´ê³ ì„œ (í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘)

## ğŸ“Š ë¶„ì„ ê°œìš”
- ë¶„ì„ í‚¤ì›Œë“œ: {keyword}
- ë¶„ì„ ì–¸ë¡ ì‚¬: {', '.join(state['selected_publishers'])}
- ë¶„ì„ ê¸°ì‚¬ ìˆ˜: {sum(len(articles) for articles in analyzed_articles.values())}ê°œ
- ë°ì´í„° ì†ŒìŠ¤: ë„¤ì´ë²„ API + RSS í”¼ë“œ

## ğŸ“° ì–¸ë¡ ì‚¬ë³„ ë³´ë„ í˜„í™©

"""
        
        # ì–¸ë¡ ì‚¬ë³„ ìƒì„¸ ì •ë³´
        for publisher, articles in analyzed_articles.items():
            if articles:
                report += f"### {publisher}\n"
                report += f"- ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ\n"
                
                # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´
                sources = {}
                for article in articles:
                    source = article.get('source', 'unknown')
                    sources[source] = sources.get(source, 0) + 1
                
                source_list = ", ".join([f"{k}({v}ê°œ)" for k, v in sources.items()])
                report += f"- ë°ì´í„° ì†ŒìŠ¤: {source_list}\n"
                
                # ê°ì • ë¶„í¬
                sentiments = [art.get('sentiment', 'ì¤‘ë¦½ì ') for art in articles]
                sentiment_count = {s: sentiments.count(s) for s in set(sentiments)}
                report += f"- ê°ì • ë¶„í¬: {sentiment_count}\n"
                
                # ì£¼ìš” ê¸°ì‚¬ ì œëª©
                report += "- ì£¼ìš” ê¸°ì‚¬:\n"
                for i, article in enumerate(articles[:2], 1):
                    report += f"  {i}. {article['title']}\n"
                
                report += "\n"
        
        # ë¹„êµ ë¶„ì„ ê²°ê³¼
        report += "## ğŸ” ì–¸ë¡ ì‚¬ ê°„ ë¹„êµ ë¶„ì„\n\n"
        report += f"**ë³´ë„ í†¤ ì°¨ì´:**\n{comparison_analysis.get('tone_differences', 'N/A')}\n\n"
        report += f"**ë…¼ì  ì°¨ì´:**\n{comparison_analysis.get('argument_differences', 'N/A')}\n\n"
        report += f"**ê°ì •ì  ì ‘ê·¼ ì°¨ì´:**\n{comparison_analysis.get('emotional_differences', 'N/A')}\n\n"
        report += f"**íŠ¹ì§•ì  ê´€ì :**\n{comparison_analysis.get('unique_perspectives', 'N/A')}\n\n"
        report += f"**ì¢…í•© ë¶„ì„:**\n{comparison_analysis.get('overall_analysis', 'N/A')}\n\n"
        
        # ë°ì´í„° ìˆ˜ì§‘ ë°©ë²•ë¡  ì¶”ê°€
        report += "## ğŸ“‹ ìˆ˜ì§‘ ë°©ë²•ë¡ \n"
        report += "- **í•˜ì´ë¸Œë¦¬ë“œ ìˆ˜ì§‘**: ë„¤ì´ë²„ ë‰´ìŠ¤ API + ì–¸ë¡ ì‚¬ë³„ RSS í”¼ë“œ\n"
        report += "- **ì¤‘ë³µ ì œê±°**: ì œëª© ê¸°ë°˜ ì¤‘ë³µ ê¸°ì‚¬ ìë™ ì œê±°\n"
        report += "- **í‚¤ì›Œë“œ í•„í„°ë§**: ê´€ë ¨ì„± ë†’ì€ ê¸°ì‚¬ë§Œ ì„ ë³„\n"
        report += "- **ì‹¤ì‹œê°„ ìˆ˜ì§‘**: ìµœì‹  ë‰´ìŠ¤ ìš°ì„  ìˆ˜ì§‘\n\n"
        
        state["final_report"] = report
        return state

    def suggest_usage(self, state: WorkflowState) -> WorkflowState:
        """
        7ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ í™œìš© ë°©ì•ˆ ì œì•ˆ
        """
        keyword = state["keyword"]
        comparison_analysis = state["comparison_analysis"]
        
        usage_prompt = f"""
í‚¤ì›Œë“œ "{keyword}"ì— ëŒ€í•œ ì–¸ë¡ ì‚¬ë³„ ë³´ë„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ë¹„êµ ë¶„ì„ ê²°ê³¼:
{json.dumps(comparison_analysis, ensure_ascii=False, indent=2)}

ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìê°€ ì–´ë–¤ ëª©ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆì„ì§€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì œì•ˆì„ í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ ì˜ì—­ë³„ë¡œ í™œìš© ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”:
1. ë¯¸ë””ì–´ ë¦¬í„°ëŸ¬ì‹œ í–¥ìƒ
2. ì—°êµ¬/í•™ìˆ  ëª©ì 
3. ë¹„ì¦ˆë‹ˆìŠ¤/ë§ˆì¼€íŒ…
4. ì •ì±…/ì˜ì‚¬ê²°ì •
5. êµìœ¡ ëª©ì 

ê° ì˜ì—­ë³„ë¡œ 2-3ê°œì˜ êµ¬ì²´ì ì¸ í™œìš© ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.llm.invoke([
                SystemMessage(content="ë‹¹ì‹ ì€ ë°ì´í„° í™œìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤."),
                HumanMessage(content=usage_prompt)
            ])
            
            usage_suggestions = self._parse_usage_suggestions(response.content)
            
        except Exception as e:
            print(f"í™œìš© ë°©ì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            usage_suggestions = [
                "ë¯¸ë””ì–´ ë¦¬í„°ëŸ¬ì‹œ: ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì˜ ë‰´ìŠ¤ë¥¼ ë¹„êµí•˜ì—¬ ê· í˜•ì¡íŒ ì‹œê° í˜•ì„±",
                "ì—°êµ¬ ëª©ì : ì–¸ë¡ ì‚¬ë³„ í”„ë ˆì´ë° íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ ê¸°ì´ˆ ë°ì´í„°",
                "êµìœ¡ ëª©ì : ë¯¸ë””ì–´ í¸í–¥ì„±ì— ëŒ€í•œ êµìœ¡ ìë£Œ"
            ]
        
        state["usage_suggestions"] = usage_suggestions
        return state

    def _clean_html(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        import re
        text = re.sub(r'<[^>]+>', '', text)
        text = text.replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
        return text.strip()

    def _parse_article_analysis(self, content: str) -> Dict[str, Any]:
        """ê¸°ì‚¬ ë¶„ì„ ê²°ê³¼ íŒŒì‹±"""
        lines = content.strip().split('\n')
        result = {
            'summary': '',
            'tone': 'ì¤‘ë¦½ì ',
            'sentiment': 'ì¤‘ë¦½ì ',
            'main_argument': '',
            'keywords': []
        }
        
        for line in lines:
            line = line.strip()
            if line.startswith('ìš”ì•½:'):
                result['summary'] = line.replace('ìš”ì•½:', '').strip()
            elif line.startswith('ì–´ì¡°:'):
                result['tone'] = line.replace('ì–´ì¡°:', '').strip()
            elif line.startswith('ê°ì •:'):
                result['sentiment'] = line.replace('ê°ì •:', '').strip()
            elif line.startswith('ì£¼ìš”ë…¼ì :'):
                result['main_argument'] = line.replace('ì£¼ìš”ë…¼ì :', '').strip()
            elif line.startswith('í‚¤ì›Œë“œ:'):
                keywords_str = line.replace('í‚¤ì›Œë“œ:', '').strip()
                result['keywords'] = [k.strip() for k in keywords_str.split(',')]
        
        return result

    def _parse_comparison_analysis(self, content: str) -> Dict[str, str]:
        """ë¹„êµ ë¶„ì„ ê²°ê³¼ íŒŒì‹±"""
        lines = content.strip().split('\n')
        result = {}
        
        for line in lines:
            line = line.strip()
            if line.startswith('ë³´ë„í†¤_ì°¨ì´:'):
                result['tone_differences'] = line.replace('ë³´ë„í†¤_ì°¨ì´:', '').strip()
            elif line.startswith('ë…¼ì _ì°¨ì´:'):
                result['argument_differences'] = line.replace('ë…¼ì _ì°¨ì´:', '').strip()
            elif line.startswith('ê°ì •_ì°¨ì´:'):
                result['emotional_differences'] = line.replace('ê°ì •_ì°¨ì´:', '').strip()
            elif line.startswith('íŠ¹ì§•ì _ê´€ì :'):
                result['unique_perspectives'] = line.replace('íŠ¹ì§•ì _ê´€ì :', '').strip()
            elif line.startswith('ì¢…í•©_ë¶„ì„:'):
                result['overall_analysis'] = line.replace('ì¢…í•©_ë¶„ì„:', '').strip()
        
        return result

    def _parse_usage_suggestions(self, content: str) -> List[str]:
        """í™œìš© ë°©ì•ˆ ì œì•ˆ íŒŒì‹±"""
        lines = content.strip().split('\n')
        suggestions = []
        
        for line in lines:
            line = line.strip()
            if line and (line.startswith('-') or line.startswith('â€¢') or line.startswith('*')):
                suggestions.append(line.lstrip('-â€¢* '))
            elif ': ' in line and not line.startswith('#'):
                suggestions.append(line)
        
        return suggestions[:10]  # ìµœëŒ€ 10ê°œ ì œì•ˆ 